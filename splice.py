# -*- coding: utf-8 -*-
"""Splice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xUZKL3I_BoZGujoVWTF-wAwudcITmWQm

## Setup
"""

# Commented out IPython magic to ensure Python compatibility.
# %load_ext autoreload
# %autoreload 2
import os
import shutil
from pathlib import Path
import imghdr



DATAROOT = "datasets/curr_pair"


from torchvision.transforms import Resize
from PIL import Image


def display_image(img):
  w, h = img.size
  if max(w, h) > 480:
    img = Resize(480, max_size=481)(img)
  display(img)

def save_image(img, path):
  w, h = img.size
  #if max(w, h) > 480:
  #  img = Resize(480, max_size=481)(img)
  img.save(path)

def process_upload(uploaded, data_path):
  if len(uploaded.keys()) > 1:
    clear_output(wait=True)
    for fn in uploaded.keys():
      os.remove(fn)
    print("Please choose 1 file!")
  else:
    fn = list(uploaded.keys())[0]
    if imghdr.what(fn) is None:
      clear_output(wait=True)
      print("Please upload a valid image file")
      os.remove(fn)
    else:
      dest_path = f"{data_path}/{fn}"
      shutil.move(fn, dest_path)
      clear_output(wait=True)
      print("Image successfully uploaded:")
      uploaded_image = Image.open(dest_path)
      display_image(uploaded_image)

from train import train_model
from torchvision.transforms import ToPILImage, Resize


texts = [
          'cow',
          ]
local_texts = [
          'cow',
          ]
for c_clip in [10, 25]:
  for i in range(len(local_texts)):
    text = texts[i]
    local_text = local_texts[i]
    filename = "{}({})ep{}c{}.png".format(text, local_text, 5000, c_clip)

    def show_result(out_img):
      img = ToPILImage()(out_img)
      save_image(img, filename)

    train_model(DATAROOT, text, local_text ,c_clip, show_result, expname=filename)
    if c_clip==0:
      break